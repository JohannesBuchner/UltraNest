{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Warm and hot start for rapid iterations\n",
    "\n",
    "In this tutorial you will learn:\n",
    "\n",
    " - How to play with model variations\n",
    " - Warm start: How UltraNest can resume and reuse an existing run, even if you modify the data/likelihood\n",
    " - Hot start: How you can make UltraNest skip ahead to the posterior peak\n",
    "\n",
    "As a simple example, lets say we want to estimate the mean and standard deviation of a sample of points. Over time, more and more points are added."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import pi, log\n",
    "\n",
    "np.random.seed(1)\n",
    "Ndata = 200\n",
    "mean_true = 42.0\n",
    "sigma_true = 0.1\n",
    "y = np.random.normal(mean_true, sigma_true, size=Ndata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise the data\n",
    "\n",
    "Lets plot the data first to see what is going on:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.errorbar(x=np.arange(Ndata), y=y, yerr=sigma_true, marker='x', ls=' ');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will ingest the data in chunks, with more and more information becoming available to us. Here are the chunks. We will first analyse the orange ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.errorbar(x=np.arange(Ndata), y=y, yerr=sigma_true, marker='x', ls=' ')\n",
    "plt.errorbar(x=np.arange(Ndata)[:10], y=y[:10], yerr=sigma_true, marker='x', ls=' ')\n",
    "ymin, ymax = plt.ylim()\n",
    "plt.vlines(np.arange(10, Ndata, 20), ymin, ymax, linestyles='--', color='gray')\n",
    "plt.ylim(ymin, ymax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultranest import ReactiveNestedSampler\n",
    "\n",
    "parameters = ['mean', 'scatter']\n",
    "\n",
    "def prior_transform(x):\n",
    "    z = np.empty_like(x)\n",
    "    z[0] = x[0] * 2000 - 1000\n",
    "    z[1] = 10**(x[1] * 4 - 2)\n",
    "    return z\n",
    "\n",
    "import scipy.stats\n",
    "def log_likelihood(params):\n",
    "    mean, sigma = params\n",
    "    return scipy.stats.norm(mean, sigma).logpdf(yseen).sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding one new chunk at a time, no warm start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_results = []\n",
    "\n",
    "for i in range(10, Ndata, 20):\n",
    "    print()\n",
    "    print(\"Iteration with %d data points\" % i)\n",
    "    yseen = y[:i]\n",
    "    sampler_ref = ReactiveNestedSampler(parameters, log_likelihood, prior_transform)\n",
    "    res_ref = sampler_ref.run(min_num_live_points=400, max_num_improvement_loops=0, viz_callback=None, frac_remain=0.5)\n",
    "    reference_results.append(res_ref)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warm start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding one data point at a time, with warm start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "yseen = y[:]\n",
    "\n",
    "# delete any existing content:\n",
    "ReactiveNestedSampler(parameters, log_likelihood, prior_transform,\n",
    "                      log_dir='warmstartdoc', resume='overwrite')\n",
    "\n",
    "for i in range(10, Ndata, 20):\n",
    "    print()\n",
    "    print(\"Iteration with %d data points\" % i)\n",
    "    \n",
    "    yseen = y[:i]\n",
    "    sampler = ReactiveNestedSampler(parameters, log_likelihood, prior_transform,\n",
    "                                    log_dir='warmstartdoc', resume='resume-similar',\n",
    "                                    warmstart_max_tau=0.5)\n",
    "    ncall_initial = int(sampler.ncall)\n",
    "    res = sampler.run(frac_remain=0.5, viz_callback=None)\n",
    "    results.append((i, res, ncall_initial))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood evaluations saved by warm start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim = len(parameters)\n",
    "plt.figure(figsize=(10, 10))\n",
    "for (i, res, ncall_initial), res_ref in zip(results, reference_results):\n",
    "    for j in range(ndim):\n",
    "        plt.subplot(ndim + 2, 1, 1+j)\n",
    "        plt.ylabel(parameters[j])\n",
    "        plt.errorbar(x=i, y=res['samples'][:,j].mean(), yerr=res['samples'][:,j].std(), marker='x', color='r')\n",
    "        plt.errorbar(x=i, y=res_ref['samples'][:,j].mean(), yerr=res_ref['samples'][:,j].std(), marker='x', color='gray')\n",
    "    \n",
    "    plt.subplot(ndim + 2, 1, 1+ndim)\n",
    "    plt.ylabel('$\\log(\\Delta Z)$')\n",
    "    plt.plot(i, res['logz'] - res_ref['logz'], 'x', color='r')\n",
    "    plt.subplot(ndim + 2, 1, 1+ndim+1)\n",
    "    plt.ylabel('Likelihood call fraction')\n",
    "    plt.plot(i, ((res['ncall'] - ncall_initial) / res_ref['ncall']), 'x', color='r')\n",
    "    plt.ylim(0, 1)\n",
    "\n",
    "plt.subplot(ndim + 2, 1, 1)\n",
    "plt.hlines(mean_true, 0, i+1, color='k', linestyles=':')\n",
    "plt.subplot(ndim + 2, 1, 2)\n",
    "plt.hlines(sigma_true, 0, i+1, color='k', linestyles=':')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take-aways:\n",
    "\n",
    "Notice the time saving in the bottom panel by more than half. This benefit is *independent of problem dimension*. The cost savings are higher, the more similar the modified problem is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hot start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may already know roughly what the posterior looks like. If it is roughly gaussian, we can take advantage of this by running UltraNest on an auxiliary distribution.\n",
    "\n",
    "The speed-up depends on how the auxiliary distribution is defined. Therefore, this is left to the user, and not automatically derived. The following illustrates how to create a auxiliary distribution and work with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guess a useful covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take result from the second-to-last run\n",
    "ref_result = reference_results[-2];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily, the posterior here is already very gaussian-like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import corner\n",
    "corner.corner(ref_result['samples'], show_titles=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1**: Identify the center and covariance (in u-space, i.e., before the prior transformation).\n",
    "\n",
    "You can also do this \n",
    "\n",
    "* by looking at the data\n",
    "* from posterior samples of a previous nested sampling or MCMC run\n",
    "* with a minimizer such as [snowline](https://johannesbuchner.github.io/snowline/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We demonstrate the second method here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.choice(len(ref_result['weighted_samples']['weights']), p=ref_result['weighted_samples']['weights'], size=10000)\n",
    "u_posterior = ref_result['weighted_samples']['upoints'][indices,:]\n",
    "ctr = u_posterior.mean(axis=0)\n",
    "cov = np.cov(u_posterior, rowvar=False)\n",
    "\n",
    "print(\"center in unit cube coordinates:\", ctr)\n",
    "print(\"center in physical coordinates:\", prior_transform(ctr))\n",
    "print(\"covariance:\", cov)\n",
    "\n",
    "invcov = np.linalg.inv(cov)\n",
    "print(\"precision matrix:\", invcov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us intentionally show the case where a poor distribution is chosen:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2**: Define the auxiliary distribution\n",
    "\n",
    "This is always the same, once you have chosen a center and covariance.\n",
    "Here we use a multivariate Student-t distribution with one degree of freedom.\n",
    "\n",
    "This allows heavier-tailed posterior distributions than a Gaussian,\n",
    "and is more forgiving if we mis-estimated the center or the covariance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultranest.hotstart import get_extended_auxiliary_problem\n",
    "\n",
    "aux_log_likelihood, aux_transform = get_extended_auxiliary_problem(\n",
    "        log_likelihood, prior_transform, ctr, invcov, \n",
    "        enlargement_factor=len(parameters)**0.5, df=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aux_parameters = ['aux_%d' % (i + 1) for i, p in enumerate(parameters)]\n",
    "aux_sampler = ReactiveNestedSampler(\n",
    "    parameters, aux_log_likelihood, transform=aux_transform,\n",
    "    derived_param_names=['aux_logweight'],\n",
    ")\n",
    "aux_results = aux_sampler.run(frac_remain=0.5, viz_callback=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getdist import MCSamples, plots\n",
    "\n",
    "aux_dist_samples_full = np.array([aux_transform(np.random.uniform(size=len(parameters))) for i in range(10000)])\n",
    "aux_dist_samples = aux_dist_samples_full[aux_dist_samples_full[:,-1] > -1e100,:-1]\n",
    "\n",
    "samples_o = MCSamples(samples=ref_result['samples'],\n",
    "                       names=ref_result['paramnames'],\n",
    "                       label='Cold start',\n",
    "                       settings=dict(smooth_scale_2D=3), sampler='nested')\n",
    "samples_a = MCSamples(samples=aux_dist_samples,\n",
    "                       names=ref_result['paramnames'],\n",
    "                       label='Auxiliary distribution',\n",
    "                       settings=dict(smooth_scale_2D=1), sampler='nested')\n",
    "samples_g = MCSamples(samples=aux_results['samples'][:,:-1],\n",
    "                       names=aux_results['paramnames'][:-1],\n",
    "                       label='Hot start',\n",
    "                       settings=dict(smooth_scale_2D=3), sampler='nested')\n",
    "\n",
    "mcsamples = [samples_o, samples_a, samples_g]\n",
    "\n",
    "g = plots.get_subplot_plotter(width_inch=8)\n",
    "g.settings.num_plot_contours = 3\n",
    "g.triangle_plot(mcsamples, filled=False, contour_colors=plt.cm.Set1.colors,\n",
    "               param_limits=dict(zip(parameters, [(41.9, 42.1), (0, 0.2)])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a good run, most auxiliary weights should be small (<1). If they are not, you may need to increase the enlargement_factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(aux_results['samples'][:,-1], bins=40)\n",
    "plt.xlabel(\"ln(weights)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed-up by hot start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming we already obtained the covariance and mean for free, what is the additional cost of the hot start?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"auxiliary sampler used %(ncall)d likelihood calls\" % aux_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this to the full run with the same number of data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Speedup factor of hot start: %.1f\" % (reference_results[-1]['ncall'] / aux_results['ncall']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This speed-up increases drastically if you have highly informative posteriors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "* Warm start allows accelerated computation based on a different but similar UltraNest run. \n",
    "* Hot start allows accelerated computation based on already approximately knowing the posterior peak.\n",
    "\n",
    "These feature allows you to:\n",
    "\n",
    "* vary the data (change the analysis pipeline)\n",
    "* vary model assumptions \n",
    "\n",
    "**without needing to start the computation from scratch** (potentially costly).\n",
    "\n",
    "These features are experimental and feedback is appreciated. It is recommended to do a full, clean run to obtain final, reliable results before publication.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
