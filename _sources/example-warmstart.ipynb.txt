{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: warm start from a similar fit\n",
    "\n",
    "In this tutorial you will learn:\n",
    "\n",
    " - How to play with model variations\n",
    " - Warm start feature: How UltraNest can resume and reuse an existing run, even if you modified the data/likelihood\n",
    "\n",
    "As a simple example, lets say we want to fit a black body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import pi, log\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Black body model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = ['Temperature', 'Amplitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def black_body_model(wavelength, ampl, T):\n",
    "    with np.errstate(over='ignore'):\n",
    "        return ampl / wavelength**5 / (np.exp(1/(wavelength*T)) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ndata = 10\n",
    "wavelength = np.logspace(1, 2, Ndata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "ampl_true = 42.0\n",
    "T_true = 0.01  # in um^-1\n",
    "background_true = 1e-9\n",
    "y_true = black_body_model(wavelength, ampl_true, T_true)\n",
    "sigma_true = y_true * 0.1\n",
    "y_obs = np.random.normal(y_true + background_true, sigma_true, size=Ndata)\n",
    "sigma = y_true * 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise the data\n",
    "\n",
    "Lets plot the data first to see what is going on:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.errorbar(x=wavelength, y=y_obs, yerr=sigma, marker='x', ls=' ')\n",
    "plt.plot(wavelength, y_true, ':', color='gray')\n",
    "plt.ylabel('Spectral flux density [Jy]');\n",
    "plt.xlabel('Wavelength [$\\mu$m]');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we intentionally set very wide priors:\n",
    "\n",
    "* a uniform prior on temperature, and \n",
    "* a very wide log-uniform prior on the normalisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior_transform(x):\n",
    "    z = x.copy()\n",
    "    z[0] = x[0]\n",
    "    z[1] = 10**(x[1] * 20 - 10)\n",
    "    return z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Prior predictive checks\")\n",
    "plt.errorbar(x=wavelength, y=y_obs, yerr=sigma, marker='x', ls=' ')\n",
    "plt.ylim(0, y_obs.max() * 10)\n",
    "\n",
    "for i in range(20):\n",
    "    T, ampl = prior_transform(np.random.uniform(size=len(parameters)))\n",
    "    y_predicted = black_body_model(wavelength, ampl, T)\n",
    "    plt.plot(wavelength, y_predicted, '-', color='gray')\n",
    "plt.ylabel('Spectral flux density [Jy]');\n",
    "plt.xlabel('Wavelength [$\\mu$m]');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(params):\n",
    "    T, ampl = params\n",
    "    y_predicted = black_body_model(wavelength, ampl, T)\n",
    "    return scipy.stats.norm(y_predicted, sigma).logpdf(y_obs).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultranest import ReactiveNestedSampler\n",
    "\n",
    "reference_run_folder = 'blackbody-alldata'\n",
    "sampler_ref = ReactiveNestedSampler(parameters, log_likelihood, prior_transform, log_dir=reference_run_folder, resume='overwrite')\n",
    "results_ref = sampler_ref.run(frac_remain=0.5)\n",
    "sampler_ref.print_results()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.errorbar(x=wavelength, y=y_obs, yerr=sigma, marker='x', ls=' ')\n",
    "from ultranest.plot import PredictionBand\n",
    "band = PredictionBand(wavelength)\n",
    "for T, ampl in results_ref['samples']:\n",
    "    band.add(black_body_model(wavelength, ampl, T))\n",
    "band.line(color='k')\n",
    "band.shade(color='k', alpha=0.5)\n",
    "plt.ylabel('Spectral flux density [Jy]');\n",
    "plt.xlabel('Wavelength [$\\mu$m]');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warm Start with Model modification\n",
    "\n",
    "Lets say we alter our model slightly. We include a small constant background:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood_with_background(params):\n",
    "    T, ampl = params\n",
    "    y_predicted = black_body_model(wavelength, ampl, T) + 1e-9\n",
    "    return scipy.stats.norm(y_predicted, sigma).logpdf(y_obs).sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the same parameters, and expect results to only be slightly different. So lets use **warm start**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the previous reference run output file ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_upoints_file = reference_run_folder + '/chains/weighted_post_untransformed.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define our accelerated likelihood and prior transform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultranest.integrator import warmstart_from_similar_file\n",
    "\n",
    "aux_paramnames, aux_log_likelihood, aux_prior_transform, vectorized = warmstart_from_similar_file(\n",
    "    posterior_upoints_file, parameters, log_likelihood_with_background, prior_transform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make accelerated run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = ReactiveNestedSampler(aux_paramnames, aux_log_likelihood, aux_prior_transform, vectorized=vectorized)\n",
    "res = sampler.run(frac_remain=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.errorbar(x=wavelength, y=y_obs, yerr=sigma, marker='x', ls=' ')\n",
    "from ultranest.plot import PredictionBand\n",
    "band = PredictionBand(wavelength)\n",
    "for T, ampl in results_ref['samples']:\n",
    "    band.add(black_body_model(wavelength, ampl, T))\n",
    "band.line(color='k')\n",
    "band.shade(color='k', alpha=0.5)\n",
    "\n",
    "band = PredictionBand(wavelength)\n",
    "for T, ampl, _ in res['samples']:\n",
    "    band.add(black_body_model(wavelength, ampl, T))\n",
    "band.line(color='orange')\n",
    "band.shade(color='orange', alpha=0.5)\n",
    "plt.plot(wavelength, y_true, ':', color='gray')\n",
    "plt.ylabel('Spectral flux density [Jy]');\n",
    "plt.xlabel('Wavelength [$\\mu$m]');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Speed-up of warm-start: %d%%\" % ((results_ref['ncall'] / res['ncall'] - 1)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cost savings are higher, the more similar the posterior of the modified run is to the original run. This speed-up increases drastically if you have highly informative posteriors.\n",
    "This benefit is *independent of problem dimension*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How it works & Limitations\n",
    "\n",
    "Warm-starting works by deforming the parameter space. The prior transform function is adjusted, and the adjustment is removed by reweighting the likelihood function, to produce the same posterior.\n",
    "To make this work, posterior samples from the unit cube space are required. The deformation uses a factorized auxiliary distribution, based on marginal posterior quantiles.\n",
    "\n",
    "The weighted_post_untransformed.txt file from a hot-started run cannot be used. This is because it has a deformation already applied.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the full documentation at\n",
    "* [warmstart_from_similar_file](https://johannesbuchner.github.io/UltraNest/ultranest.html#ultranest.integrator.warmstart_from_similar_file ) and\n",
    "* the underlying [get_auxiliary_contbox_parameterization](https://johannesbuchner.github.io/UltraNest/ultranest.html#ultranest.hotstart.get_auxiliary_contbox_parameterization) function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting from existing posterior samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "If you already have posterior samples, then you can create an appropriate weighted_post_untransformed.txt file.\n",
    "However, the inverse of the prior transformation has to be applied.\n",
    "\n",
    "In some cases, this is easy to do analytically, e.g., for uniform priors it is just a scaling.\n",
    "\n",
    "The following code works for arbitrary, factorized priors (as in the blackbody example in this notebook), for an arbitrary number of parameters.\n",
    "\n",
    "Lets start with our posterior samples. These could be obtained posterior samples from MCMC, or generated from the parameter errors quoted in a paper. Here we take it from the reference run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples = results_ref['samples']\n",
    "\n",
    "plt.scatter(posterior_samples[:,0], posterior_samples[:,1]);\n",
    "plt.xlabel('%s (p-space)' % parameters[0])\n",
    "plt.ylabel('%s (p-space)' % parameters[1]);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a look how our unit-cube prior transform works:\n",
    "\n",
    "The first parameter has a uniform prior, the other a log-uniform prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uguess = np.linspace(1e-6, 1-1e-6, 40000)\n",
    "pguess = np.array([prior_transform(ui * np.ones(len(parameters))) for ui in uguess])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(uguess, pguess[:,0])\n",
    "plt.xlabel('u-space (%s)' % parameters[0])\n",
    "plt.ylabel('p-space (%s)' % parameters[0]);\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(uguess, pguess[:,1])\n",
    "plt.xlabel('u-space (%s)' % parameters[1])\n",
    "plt.ylabel('p-space (%s)' % parameters[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we convert the posterior samples to u-space, by finding the unit-cube value by optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nparams = len(parameters)\n",
    "u = np.ones(nparams) * 0.5\n",
    "stdevs = posterior_samples.std(axis=0)\n",
    "\n",
    "def minfunc(ui, i, u, pi):\n",
    "    u[i] = ui\n",
    "    p = prior_transform(u)\n",
    "    return (p[i] - pi)**2\n",
    "\n",
    "usamples = np.empty((len(posterior_samples), nparams))\n",
    "for j, sample in enumerate(tqdm.tqdm(posterior_samples)):\n",
    "    for i, param in enumerate(parameters):\n",
    "        ui0 = np.interp(sample[i], pguess[:,i], uguess)\n",
    "        result = scipy.optimize.minimize_scalar(\n",
    "            minfunc, \n",
    "            args=(i, u, sample[i]), \n",
    "            method='brent',\n",
    "            bounds=(0,1),\n",
    "            bracket=(ui0 - 1e-4, ui0, ui0 + 1e-4),\n",
    "            tol=0.001 * stdevs[i],\n",
    "        )\n",
    "        usamples[j,i] = result.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see whether our untransformed (u-space) posterior samples are correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = results_ref['weighted_samples']['weights']\n",
    "i = np.random.choice(len(weights), p=weights, size=1000)\n",
    "plt.scatter(results_ref['weighted_samples']['upoints'][i,0], results_ref['weighted_samples']['upoints'][i,1], \n",
    "            color='gray', label='reference run');\n",
    "\n",
    "plt.scatter(usamples[:,0], usamples[:,1], label='modified run, usamples reconstructed', marker='x', alpha=0.5)\n",
    "plt.xlabel('u-space (%s)' % parameters[0])\n",
    "plt.ylabel('u-space (%s)' % parameters[1])\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like great agreement! We successfully untransformed the posterior samples to u-space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing a run file for warm start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write a weighted_post_untransformed.txt file based on our untransformed posterior samples. Since these are equally weighted, the first two columns are constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.ones((len(usamples), 1)) / len(usamples)\n",
    "logl = np.zeros(len(usamples)).reshape((-1, 1))\n",
    "\n",
    "np.savetxt(\n",
    "    'custom-weighted_post_untransformed.txt',\n",
    "    np.hstack((weights, logl, usamples)),\n",
    "    header=' '.join(['weight', 'logl'] + parameters),\n",
    "    fmt='%f'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head custom-weighted_post_untransformed.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now point the warmstart_from_similar_file function at this file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Warm start allows accelerated computation based on already knowing the posterior peak approximately. This allows you to:\n",
    "\n",
    "* vary the data (change the analysis pipeline)\n",
    "* vary model assumptions \n",
    "\n",
    "without needing to start the computation from scratch (potentially costly).\n",
    "\n",
    "These features are experimental and feedback is appreciated. It is recommended to do a full, clean run to obtain final, reliable results before publication.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
