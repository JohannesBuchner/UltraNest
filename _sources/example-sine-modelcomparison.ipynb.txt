{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "We again consider the sine model with gaussian measurement errors.\n",
    "\n",
    "$$ y = A_1 \\sin\\left(2 \\pi \\left(\\frac{t}{P_1} + t_1\\right)\\right) + B + \\epsilon $$\n",
    "\n",
    "where $\\epsilon \\sim \\mathrm{Normal}(0, \\sigma)$\n",
    "\n",
    "We want to test if this is preferred over pure noise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import pi, sin\n",
    "\n",
    "def sine_model1(t, B, A1, P1, t1):\n",
    "    return A1 * sin((t / P1 + t1) * 2 * pi) + B\n",
    "\n",
    "def sine_model0(t, B):\n",
    "    return B + t*0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The model has four unknown parameters per component:\n",
    "\n",
    "* the signal offset $B$\n",
    "* the amplitude $A$\n",
    "* the period $P$\n",
    "* the time offset $t_0$\n",
    "\n",
    "## Generating data\n",
    "\n",
    "Lets generate some data following this model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n_data = 50\n",
    "\n",
    "# time of observations\n",
    "t = np.random.uniform(0, 5, size=n_data)\n",
    "# measurement values\n",
    "yerr = 1.0\n",
    "y = np.random.normal(sine_model1(t, B=1.0, A1=0.9, P1=3, t1=0), yerr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise the data\n",
    "\n",
    "Lets plot the data first to see what is going on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.errorbar(x=t, y=y, yerr=yerr,\n",
    "             marker='o', ls=' ', color='orange')\n",
    "t_range = np.linspace(0, 5, 1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A beautiful noisy data set, with some hints of a modulation.\n",
    "\n",
    "Now the question is: what model parameters are allowed under these data?\n",
    "\n",
    "First, we need to define the parameter ranges through a prior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters1 = ['B', 'A1', 'P1', 't1']\n",
    "\n",
    "def prior_transform1(cube):\n",
    "    # the argument, cube, consists of values from 0 to 1\n",
    "    # we have to convert them to physical scales\n",
    "    \n",
    "    params = cube.copy()\n",
    "    # let background level go from -10 to +10\n",
    "    params[0] = cube[0] * 20 - 10\n",
    "    # let amplitude go from 0.1 to 100\n",
    "    params[1] = 10**(cube[1] * 3 - 1)\n",
    "    # let period go from 0.3 to 30\n",
    "    params[2] = 10**(cube[2] * 2)\n",
    "    # let time go from 0 to 1\n",
    "    params[3] = cube[3]\n",
    "    return params\n",
    "\n",
    "parameters0 = ['B']\n",
    "\n",
    "def prior_transform0(cube):\n",
    "    # the argument, cube, consists of values from 0 to 1\n",
    "    # we have to convert them to physical scales\n",
    "    \n",
    "    params = cube.copy()\n",
    "    # let background level go from -10 to +10\n",
    "    params[0] = cube[0] * 20 - 10\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the likelihood, which measures how far the data are from the model predictions.\n",
    "More precisely, how often the parameters would arise under the given parameters.\n",
    "We assume gaussian measurement errors of known size (yerr).\n",
    "\n",
    "$$\\chi^2 = \\sum\\left(\\frac{m_i-y_i}{\\sigma}\\right)^2 $$\n",
    "$$\\log \\cal{L} = -\\chi^2 / 2$$\n",
    "\n",
    "where the model is the sine_model function from above at time $t_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood1(params):\n",
    "    # unpack the current parameters:\n",
    "    B, A1, P1, t1 = params\n",
    "\n",
    "    # compute for each x point, where it should lie in y\n",
    "    y_model = sine_model1(t, B=B, A1=A1, P1=P1, t1=t1)\n",
    "    # compute likelihood\n",
    "    loglike = -0.5 * (((y_model - y) / yerr)**2).sum()\n",
    "    \n",
    "    return loglike\n",
    "\n",
    "def log_likelihood0(params):\n",
    "    B, = params\n",
    "    \n",
    "    y_model = sine_model0(t, B=B)\n",
    "    # compute likelihood\n",
    "    loglike = -0.5 * (((y_model - y) / yerr)**2).sum()\n",
    "    \n",
    "    return loglike\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve the problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultranest\n",
    "\n",
    "sampler1 = ultranest.ReactiveNestedSampler(parameters1, log_likelihood1, prior_transform1)\n",
    "\n",
    "sampler0 = ultranest.ReactiveNestedSampler(parameters0, log_likelihood0, prior_transform0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = sampler1.run(min_num_live_points=400)\n",
    "sampler1.print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result0 = sampler0.run(min_num_live_points=400)\n",
    "sampler0.print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the parameter posterior probability distribution\n",
    "\n",
    "A classic corner plot of the parameter pairs and the marginal distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultranest.plot import cornerplot\n",
    "cornerplot(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cornerplot(result0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want, you can also play with the posterior as a pandas frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data=result1['samples'], columns=result1['paramnames'])\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the fit:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate whether the results make any sense, we want\n",
    "to look whether the fitted function goes through the data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"1-sine fit\")\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.errorbar(x=t, y=y, yerr=yerr,\n",
    "             marker='o', ls=' ', color='orange')\n",
    "\n",
    "\n",
    "t_grid = np.linspace(0, 5, 400)\n",
    "\n",
    "from ultranest.plot import PredictionBand\n",
    "band = PredictionBand(t_grid)\n",
    "\n",
    "# go through the solutions\n",
    "for B, A1, P1, t1 in sampler1.results['samples']:\n",
    "    # compute for each time the y value\n",
    "    band.add(sine_model1(t_grid, B=B, A1=A1, P1=P1, t1=t1))\n",
    "\n",
    "band.line(color='k')\n",
    "# add 1 sigma quantile\n",
    "band.shade(color='k', alpha=0.3)\n",
    "# add wider quantile (0.01 .. 0.99)\n",
    "band.shade(q=0.49, color='gray', alpha=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "## Model comparison methods\n",
    "\n",
    "We now want to know:\n",
    "\n",
    "**Is the model with 2 components better than the model with one component?**\n",
    "\n",
    "What do we mean by \"better\" (\"it fits better\", \"the component is significant\")?\n",
    "\n",
    "a) Which model is better at predicting data it has not seen yet?\n",
    "\n",
    "b) Which model is more probably the true one, given this data, these models, and their parameter spaces?\n",
    "\n",
    "c) Which model is simplest, but complex enough to capture the information complexity of the data?\n",
    "\n",
    "\n",
    "## Bayesian model comparison\n",
    "\n",
    "Here we will focus on b, and apply Bayesian model comparison. \n",
    "\n",
    "For simplicity, we will assume equal a-prior model probabilities.\n",
    "\n",
    "The Bayes factor is:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = np.exp(result1['logz'] - result0['logz'])\n",
    "print(\"K = %.2f\" % K)\n",
    "print(\"The 1-sine model is %.2f times more probable than the no-signal model\" % K)\n",
    "print(\"assuming the models are equally probable a priori.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N.B.: Bayes factors are influenced by parameter and model priors. It is a good idea to vary them and see how sensitive the result is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For making decisions, thresholds are needed. They can be calibrated to desired low false decisions rates with simulations (generate data under the simpler model, look at K distribution)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibrating Bayes factor thresholds\n",
    "\n",
    "Lets generate some data sets under the null hypothesis (noise-only model) and see \n",
    "how often we would get a large Bayes factor. For this, we need to fit with both \n",
    "models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger('ultranest').setLevel(logging.FATAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_simulated = []\n",
    "\n",
    "import logging\n",
    "logging.getLogger('ultranest').handlers[-1].setLevel(logging.FATAL)\n",
    "\n",
    "# go through 100 plausible parameters\n",
    "for B in sampler0.results['samples'][:10]:\n",
    "    # generate new data\n",
    "    y = np.random.normal(sine_model0(t, B=1.0), yerr)\n",
    "    \n",
    "    # analyse with sine model\n",
    "    sampler1 = ultranest.ReactiveNestedSampler(parameters1, log_likelihood1, prior_transform1)\n",
    "    Z1 = sampler1.run(viz_callback=False)['logz']\n",
    "    # analyse with noise-only model\n",
    "    sampler0 = ultranest.ReactiveNestedSampler(parameters0, log_likelihood0, prior_transform0)\n",
    "    Z0 = sampler0.run(viz_callback=False)['logz']\n",
    "    # store Bayes factor\n",
    "    K_here = Z1 - Z0\n",
    "    K_simulated.append(K_here)\n",
    "    print()\n",
    "    print(\"Bayes factor: %.2f\" % np.exp(K_here))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(np.exp(K_simulated), histtype='step', label='From simulated noise data')\n",
    "ylo, yhi = plt.ylim()\n",
    "plt.vlines(K, ylo, yhi, label='From our real data')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Bayes factor')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(loc='upper center');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we run this a bit longer, we will fill in the simulation histogram better. But already now we can see:\n",
    "\n",
    "We are using simulations to measure how often, by chance, we would see a Bayes factor higher than the one we observe. By building up a histogram, we can get a p-value, telling us our false decision rate for any Bayes factor threshold. \n",
    "Thus, we are putting a frequentist property on our Bayesian inference-based decision. \n",
    "\n",
    "So I would say: \n",
    "**Pure noise does not produce as high a Bayes factor as we see it in the real data.**\n",
    "\n",
    "Calibrating Bayes factor thresholds reduces the dependence on model priors and model parameter priors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further reading\n",
    "\n",
    "* Buchner+14 https://arxiv.org/abs/1402.0004 (§5.2, Appendix C for calibration)\n",
    "* Trotta+08 https://arxiv.org/abs/0803.4089\n",
    "* https://en.wikipedia.org/wiki/Bayes_factor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
