{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: intrinsic distribution\n",
    "\n",
    "In this tutorial you will learn:\n",
    "\n",
    " - How to find a intrinsic distribution from data with asymmetric error bars and upper limits\n",
    " - How to use UltraNest\n",
    " - How to test whether there are two sub-populations\n",
    "\n",
    "Lets say we want to find the intrinsic velocity dispersion given some noisy data points.\n",
    "\n",
    "Our data are velocity measurements of a few globular cluster velocities in a dwarf galaxy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# velocity dispersions of dwarf galaxies by van Dokkum et al., Nature, 555, 629 https://arxiv.org/abs/1803.10237v1\n",
    "\n",
    "values = np.array([15, 4, 2, 11, 1, -2, -1, -14, -39, -3])\n",
    "values_lo = np.array([7, 16, 6, 3, 6, 5, 10, 6, 11, 13])\n",
    "values_hi = np.array([7, 15, 8, 3, 6, 6, 10, 7, 14, 14])\n",
    "\n",
    "n_data = len(values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise the data\n",
    "\n",
    "Lets plot the data first to see what is going on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "xlabel = 'Velocity [km/s]'\n",
    "plt.xlabel(xlabel)\n",
    "plt.errorbar(x=values, xerr=[values_lo, values_hi], y=range(n_data), \n",
    "             marker='o', ls=' ', color='orange')\n",
    "plt.xlim(-50, 50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data properties\n",
    "\n",
    "This scatter plot shows: \n",
    "\n",
    "* large, sometimes asymmetric error bars\n",
    "* intrinsic scatter\n",
    "\n",
    "### Resampling the data\n",
    "\n",
    "We could also represent each data point by a cloud of samples.\n",
    "Each point represents a possible true solution of that galaxy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "\n",
    "for i in range(n_data):\n",
    "    # draw normal random points\n",
    "    u = np.random.normal(size=400)\n",
    "    v = values[i] + np.where(u < 0, u * values_lo[i], u * values_hi[i])\n",
    "    \n",
    "    samples.append(v)\n",
    "\n",
    "samples = np.array(samples)\n",
    "    \n",
    "plt.figure()\n",
    "# for each galaxy, plot alittle cloud with its own colors\n",
    "plt.violinplot(samples.transpose(), vert=False, showextrema=False)\n",
    "\n",
    "plt.xlabel(xlabel);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Lets fit a intrinsic, gaussian distribution.\n",
    "\n",
    "$$ y \\sim \\mathrm{Normal}(\\mu, \\sigma) $$\n",
    "\n",
    "The model has two unknown parameters:\n",
    "\n",
    "* the mean $\\mu$\n",
    "* the scatter $\\sigma$\n",
    "\n",
    "Lets write down prior ranges for these parameters:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = ['mean', 'scatter']\n",
    "\n",
    "def prior_transform(cube):\n",
    "    # the argument, cube, consists of values from 0 to 1\n",
    "    # we have to convert them to physical scales\n",
    "    \n",
    "    params = cube.copy()\n",
    "    # let slope go from -3 to +3\n",
    "    lo = -100\n",
    "    hi = +100\n",
    "    params[0] = cube[0] * (hi - lo) + lo\n",
    "    # let scatter go from 1 to 1000\n",
    "    lo = np.log10(1)\n",
    "    hi = np.log10(1000)\n",
    "    params[1] = 10**(cube[1] * (hi - lo) + lo)\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the likelihood, which measures how far the data are from the model predictions.\n",
    "More precisely, how often the parameters would arise under the given parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "def log_likelihood(params):\n",
    "    # unpack the current parameters:\n",
    "    mean, scatter = params\n",
    "\n",
    "    # compute the probability of each sample\n",
    "    probs_samples = scipy.stats.norm(mean, scatter).pdf(samples)\n",
    "    # average over each galaxy, because we assume one of the points is the correct one (logical OR)\n",
    "    probs_objects = probs_samples.mean(axis=1)\n",
    "    assert len(probs_objects) == n_data\n",
    "    # multiply over the galaxies, because we assume our model holds true for all objects (logical AND)\n",
    "    # for numerical stability, we work in log and avoid zeros\n",
    "    loglike = np.log(probs_objects + 1e-100).sum()\n",
    "    return loglike\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This likelihood evaluates the model for each object at each sample, and averages the model densities. This corresponds to saying: I don't know which of these options is correct, but I assume one of them is, so by using a logical OR, I sum the probabilities.\n",
    "\n",
    "The objects are then combined by multiplying the per-object probabilities. This corresponds to saying: I know the model has to describe all of these objects, so using a logical AND, I multiply the probabilities. Here we convert to log space, and sum. The small number is added to gracefully handle when a object probability is zero (distant means and small sigma).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultranest\n",
    "\n",
    "sampler = ultranest.ReactiveNestedSampler(parameters, log_likelihood, prior_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets first try with relatively poor sampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sampler.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultranest.plot import cornerplot\n",
    "cornerplot(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ask for more samples: increasing the required effective sample size\n",
    "result = sampler.run(min_ess=4000)\n",
    "cornerplot(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the 3 sigma upper limit on the scatter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_samples, scatter_samples = result['samples'].transpose()\n",
    "\n",
    "# get 3 sigma quantile\n",
    "quantile = scipy.stats.norm().cdf(3)\n",
    "\n",
    "# look at the value:\n",
    "print('scatter is < %.4f km/s at 3 sigma (%.3f%% quantile)' % (scipy.stats.mstats.mquantiles(scatter_samples, quantile), quantile*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.errorbar(x=values, xerr=[values_lo, values_hi], y=range(n_data), \n",
    "             marker='o', ls=' ', color='orange')\n",
    "plt.xlim(-100, 100)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.xlim(-100, 100)\n",
    "plt.xlabel(xlabel)\n",
    "\n",
    "from ultranest.plot import PredictionBand\n",
    "x = np.linspace(-100, 100, 400)\n",
    "band = PredictionBand(x)\n",
    "bandc = PredictionBand(x)\n",
    "\n",
    "for params in sampler.results['samples'][:40]:\n",
    "    mean, scatter = params\n",
    "    band.add(scipy.stats.norm(mean, scatter).pdf(x))\n",
    "\n",
    "band.shade(color='k', alpha=0.1)\n",
    "band.line(color='k');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next\n",
    "\n",
    "1. Try adjusting the number of live points (min_num_live_points) and effective sample size (min_ess) parameters above to decrease the uncertainties.\n",
    "2. Try different models -- student-t distribution instead of normal, mixture of two gaussians\n",
    "3. Try varying the prior ranges.\n",
    "4. Continue with the other tutorials and explore other UltraNest features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
