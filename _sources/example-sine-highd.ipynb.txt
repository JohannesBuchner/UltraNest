{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Higher-dimensional fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "We again consider the sine model with gaussian measurement errors.\n",
    "\n",
    "$$ y = A_1 \\sin\\left(2 \\pi \\left(\\frac{t}{P_1} + t_1\\right)\\right) + B + \\epsilon $$\n",
    "\n",
    "where $\\epsilon \\sim \\mathrm{Normal}(0, \\sigma)$\n",
    "\n",
    "We want to test if there is another sine component present:\n",
    "\n",
    "$$ y = A_1 \\sin\\left(2 \\pi \\left(\\frac{t}{P_1} + t_1\\right)\\right) + A_2 \\sin\\left(2 \\pi \\left(\\frac{t}{P_2} + t_2\\right)\\right) + B + \\epsilon $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import sin, pi\n",
    "\n",
    "def sine_model1(t, B, A1, P1, t1):\n",
    "    return A1 * sin((t / P1 + t1) * 2 * pi) + B\n",
    "\n",
    "def sine_model2(t, B, A1, P1, t1, A2, P2, t2):\n",
    "    return A1 * sin((t / P1 + t1) * 2 * pi) + A2 * sin((t / P2 + t2) * 2 * pi) + B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The model has four unknown parameters per component:\n",
    "\n",
    "* the signal offset $B$\n",
    "* the amplitude $A$\n",
    "* the period $P$\n",
    "* the time offset $t_0$\n",
    "\n",
    "As we will see, the second component makes the 7-dimensional parameter space already quite challenging to explore.\n",
    "\n",
    "## Generating data\n",
    "\n",
    "Lets generate some data following this model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "n_data = 50\n",
    "\n",
    "# time of observations\n",
    "t = np.random.uniform(0, 5, size=n_data)\n",
    "# measurement values\n",
    "yerr = 1.0\n",
    "y = np.random.normal(sine_model2(t, B=1.0, A1=4.2, P1=3, t1=0, A2=1.2, P2=1.2, t2=1.2), yerr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise the data\n",
    "\n",
    "Lets plot the data first to see what is going on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.errorbar(x=t, y=y, yerr=yerr,\n",
    "             marker='o', ls=' ', color='orange')\n",
    "t_range = np.linspace(0, 5, 1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A beautiful noisy data set, but we can see the modulation.\n",
    "\n",
    "Now the question is: what model parameters are allowed under these data?\n",
    "\n",
    "First, we need to define the parameter ranges through a prior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters1 = ['B', 'A1', 'P1', 't1']\n",
    "\n",
    "def prior_transform1(cube):\n",
    "    # the argument, cube, consists of values from 0 to 1\n",
    "    # we have to convert them to physical scales\n",
    "    \n",
    "    params = cube.copy()\n",
    "    # let background level go from -10 to +10\n",
    "    params[0] = cube[0] * 20 - 10\n",
    "    # let amplitude go from 0.1 to 100\n",
    "    params[1] = 10**(cube[1] * 3 - 1)\n",
    "    # let period go from 0.3 to 30\n",
    "    params[2] = 10**(cube[2] * 2)\n",
    "    # let time go from 0 to 1\n",
    "    params[3] = cube[3]\n",
    "    return params\n",
    "\n",
    "parameters2 = ['B', 'A1', 'P1', 't1', 'A2', 'P2', 't2']\n",
    "\n",
    "def prior_transform2(cube):\n",
    "    # the argument, cube, consists of values from 0 to 1\n",
    "    # we have to convert them to physical scales\n",
    "    \n",
    "    params = cube.copy()\n",
    "    # let background level go from -10 to +10\n",
    "    params[0] = cube[0] * 20 - 10\n",
    "    # let amplitude go from 0.1 to 100\n",
    "    params[1] = 10**(cube[1] * 3 - 1)\n",
    "    # let period go from 0.3 to 30\n",
    "    params[2] = 10**(cube[2] * 2)\n",
    "    # let time go from 0 to 1\n",
    "    params[3] = cube[3]\n",
    "\n",
    "    # let amplitude go from 0.01 to 100\n",
    "    params[4] = 10**(cube[4] * 3 - 1)\n",
    "    # let period go from 0.3 to 30\n",
    "    params[5] = 10**(cube[5] * 2)\n",
    "    # let time go from 0 to 1\n",
    "    params[6] = cube[6]\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the likelihood, which measures how far the data are from the model predictions.\n",
    "More precisely, how often the parameters would arise under the given parameters.\n",
    "We assume gaussian measurement errors of known size (yerr).\n",
    "\n",
    "$$\\chi^2 = \\sum\\left(\\frac{m_i-y_i}{\\sigma}\\right)^2 $$\n",
    "$$\\log \\cal{L} = -\\chi^2 / 2$$\n",
    "\n",
    "where the model is the sine_model function from above at time $t_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "def log_likelihood1(params):\n",
    "    # unpack the current parameters:\n",
    "    B, A1, P1, t1 = params\n",
    "\n",
    "    # compute for each x point, where it should lie in y\n",
    "    y_model = sine_model1(t, B=B, A1=A1, P1=P1, t1=t1)\n",
    "    # compute likelihood\n",
    "    loglike = -0.5 * (((y_model - y) / yerr)**2).sum()\n",
    "    \n",
    "    return loglike\n",
    "\n",
    "def log_likelihood2(params):\n",
    "    # unpack the current parameters:\n",
    "    B, A1, P1, t1, A2, P2, t2 = params\n",
    "    \n",
    "    # avoid unnecessary multiple solutions:\n",
    "    #    force ordering by period from large to small\n",
    "    if P1 < P2:\n",
    "        return -1e300\n",
    "    \n",
    "    # compute for each x point, where it should lie in y\n",
    "    y_model = sine_model2(t, B=B, A1=A1, P1=P1, t1=t1, A2=A2, P2=P2, t2=t2)\n",
    "    # compute likelihood\n",
    "    loglike = -0.5 * (((y_model - y) / yerr)**2).sum()\n",
    "    \n",
    "    return loglike\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve the problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultranest\n",
    "\n",
    "sampler1 = ultranest.ReactiveNestedSampler(\n",
    "    parameters1, \n",
    "    log_likelihood1, prior_transform1,\n",
    "    wrapped_params=[False, False, False, True],\n",
    ")\n",
    "\n",
    "sampler2 = ultranest.ReactiveNestedSampler(\n",
    "    parameters2,\n",
    "    log_likelihood2,\n",
    "    prior_transform2,\n",
    "    wrapped_params=[False, False, False, True, False, False, True],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we solve the simpler model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = sampler1.run(min_num_live_points=400)\n",
    "sampler1.print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets have a go at the harder problem. We limit the number of evaluations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = sampler2.run(min_num_live_points=400, max_ncalls=400000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The efficiency is very low. This is not just because of the dimensionality of the problem, but also because of the degeneracies. To make progress, lets use a slice sampler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultranest.stepsampler\n",
    "\n",
    "# have to choose the number of steps the slice sampler should take\n",
    "# after first results, this should be increased and checked for consistency.\n",
    "\n",
    "nsteps = 2 * len(parameters2)\n",
    "# create step sampler:\n",
    "sampler2.stepsampler = ultranest.stepsampler.RegionSliceSampler(nsteps=nsteps)\n",
    "\n",
    "# alternatively, we can let the sample identify the number of steps needed on the fly:\n",
    "# This is done by requiring the point to move at least the typical distance\n",
    "# between live points, on average.\n",
    "#sampler2.stepsampler = ultranest.stepsampler.RegionSliceSampler(nsteps=400, adaptive_nsteps='move-distance')\n",
    "\n",
    "\n",
    "# run again:\n",
    "result2 = sampler2.run(min_num_live_points=400)\n",
    "sampler2.print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The efficiency is now constant (at 1/nsteps)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the parameter posterior probability distribution\n",
    "\n",
    "A classic corner plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultranest.plot import cornerplot\n",
    "cornerplot(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cornerplot(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler1.ncall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate whether the results make any sense, we want\n",
    "to look whether the fitted function goes through the data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"1-sine fit\")\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.errorbar(x=t, y=y, yerr=yerr,\n",
    "             marker='o', ls=' ', color='orange')\n",
    "\n",
    "\n",
    "t_grid = np.linspace(0, 5, 400)\n",
    "\n",
    "from ultranest.plot import PredictionBand\n",
    "band = PredictionBand(t_grid)\n",
    "\n",
    "# go through the solutions\n",
    "for B, A1, P1, t1 in sampler1.results['samples']:\n",
    "    # compute for each time the y value\n",
    "    band.add(sine_model1(t_grid, B=B, A1=A1, P1=P1, t1=t1))\n",
    "\n",
    "band.line(color='k')\n",
    "# add 1 sigma quantile\n",
    "band.shade(color='k', alpha=0.3)\n",
    "# add wider quantile (0.01 .. 0.99)\n",
    "band.shade(q=0.49, color='gray', alpha=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"2-sine fit\")\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.errorbar(x=t, y=y, yerr=yerr,\n",
    "             marker='o', ls=' ', color='orange')\n",
    "\n",
    "band = PredictionBand(t_grid)\n",
    "\n",
    "# go through the solutions\n",
    "for B, A1, P1, t1, A2, P2, t2 in sampler2.results['samples']:\n",
    "    # compute for each time the y value\n",
    "    band.add(sine_model2(t_grid, B=B, A1=A1, P1=P1, t1=t1, A2=A2, P2=P2, t2=t2))\n",
    "\n",
    "band.line(color='k')\n",
    "# add 1 sigma quantile\n",
    "band.shade(color='k', alpha=0.3)\n",
    "# add wider quantile (0.01 .. 0.99)\n",
    "band.shade(q=0.49, color='gray', alpha=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "## Model comparison\n",
    "\n",
    "We now want to know:\n",
    "\n",
    "**Is the model with 2 components better than the model with one component?**\n",
    "\n",
    "What do we mean by \"better\" (\"it fits better\", \"the second component is significant\")?\n",
    "\n",
    "a) Which model is better at predicting data it has not seen yet?\n",
    "\n",
    "b) Which model is more probably the true one, given this data, and these models (and their parameter spaces)?\n",
    "\n",
    "c) Which model is simplest, but complex enough to capture the information complexity of the data?\n",
    "\n",
    "\n",
    "## Bayesian model comparison\n",
    "\n",
    "Here we will focus on b, and apply Bayesian model comparison. \n",
    "\n",
    "For simplicity, we will assume equal a-prior model probabilities.\n",
    "\n",
    "The Bayes factor is:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = np.exp(result2['logz'] - result1['logz'])\n",
    "K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us, assuming both models are equally probable a-priori, that \n",
    "the 2-sine model is 150 times more probable to be the true model than the 1-sine model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N.B.: Bayes factors are influenced by parameter and model priors. It is a good idea to vary them and see how sensitive the result is. Here, the factor is extremely large, so we can be fairly confident that the 2-sine model is correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For making decisions, thresholds are needed. They can be calibrated to desired low false decisions rates with simulations (generate data under the simpler model, look at K distribution)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
