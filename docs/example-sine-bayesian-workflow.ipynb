{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian workflow\n",
    "\n",
    "This tutorial highlights some ideas from https://arxiv.org/abs/1709.01449, including:\n",
    "\n",
    "* Making a flip book of the prior predictions\n",
    "* posterior predictive checks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "We again consider the sine model with gaussian measurement errors.\n",
    "\n",
    "$$ y = A_1 \\sin\\left(2 \\pi \\left(\\frac{t}{P_1} + t_1\\right)\\right) + B + \\epsilon $$\n",
    "\n",
    "where $\\epsilon \\sim \\mathrm{Normal}(0, \\sigma)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import pi, sin\n",
    "\n",
    "def sine_model1(t, B, A1, P1, t1):\n",
    "    return A1 * sin((t / P1 + t1) * 2 * pi) + B\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The model has four unknown parameters per component:\n",
    "\n",
    "* the signal offset $B$\n",
    "* the amplitude $A$\n",
    "* the period $P$\n",
    "* the time offset $t_0$\n",
    "\n",
    "## Generating data\n",
    "\n",
    "Lets generate some data following this model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n_data = 50\n",
    "\n",
    "# time of observations\n",
    "t = np.random.uniform(0, 5, size=n_data)\n",
    "# measurement values\n",
    "yerr = 1.0\n",
    "y = np.random.normal(sine_model1(t, B=1.0, A1=0.9, P1=3, t1=0), yerr)\n",
    "\n",
    "y[0] += 3  # add outlier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise the data\n",
    "\n",
    "Lets plot the data first to see what is going on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.errorbar(x=t, y=y, yerr=yerr,\n",
    "             marker='o', ls=' ', color='orange')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A beautiful noisy data set, with some hints of a modulation.\n",
    "\n",
    "Given this data set, we should come up with a sensible model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = ['B', 'A1', 'P1', 't1']\n",
    "\n",
    "def prior_transform(cube):\n",
    "    # the argument, cube, consists of values from 0 to 1\n",
    "    # we have to convert them to physical scales\n",
    "    \n",
    "    params = cube.copy()\n",
    "    # let background level go from -10 to +10\n",
    "    params[0] = cube[0] * 20 - 10\n",
    "    # let amplitude go from 0.1 to 100\n",
    "    params[1] = 10**(cube[1] * 3 - 1)\n",
    "    # let period go from 0.3 to 30\n",
    "    params[2] = 10**(cube[2] * 2)\n",
    "    # let time go from 0 to 1\n",
    "    params[3] = cube[3]\n",
    "    return params\n",
    "\n",
    "def log_likelihood(params):\n",
    "    # unpack the current parameters:\n",
    "    B, A1, P1, t1 = params\n",
    "\n",
    "    # compute for each x point, where it should lie in y\n",
    "    y_model = sine_model1(t, B=B, A1=A1, P1=P1, t1=t1)\n",
    "    # compute likelihood\n",
    "    loglike = -0.5 * (((y_model - y) / yerr)**2).sum()\n",
    "    \n",
    "    return loglike\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a few samples from the prior and look if they look anything like data we would expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    plt.figure()\n",
    "    cube = np.random.uniform(size=len(parameters))\n",
    "    params = prior_transform(cube)\n",
    "    B, A1, P1, t1 = params\n",
    "    y_model = sine_model1(t, B=B, A1=A1, P1=P1, t1=t1)\n",
    "    y_sim = np.random.normal(y_model, yerr)\n",
    "\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.errorbar(x=t, y=y_sim, yerr=yerr,\n",
    "                 marker='o', ls=' ')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks quite OK actually -- the y-ranges are of the right magnitude, the periods are sometimes short, sometimes long."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultranest\n",
    "\n",
    "sampler = ultranest.ReactiveNestedSampler(parameters, log_likelihood, prior_transform)\n",
    "result = sampler.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior predictive checks\n",
    "\n",
    "The idea of posterior predictive checks (PPC)\n",
    "is to generate new data from each posterior sample,\n",
    "and then verify if they look like the data.\n",
    "\n",
    "This is a bit circular, but if the model is too rigid,\n",
    "then some data points cannot be reproduced.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultranest.plot import PredictionBand\n",
    "\n",
    "t_range = np.linspace(0, 5, 100)\n",
    "band = PredictionBand(t_range)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "for params in result['samples']:\n",
    "    B, A1, P1, t1 = params\n",
    "    y_model = sine_model1(t_range, B=B, A1=A1, P1=P1, t1=t1)\n",
    "    y_sim = np.random.normal(y_model, yerr)\n",
    "    band.add(y_sim)\n",
    "\n",
    "band.line(color='g')\n",
    "band.shade(color='g', alpha=0.5)\n",
    "band.shade(q=0.49, color='g', alpha=0.5)\n",
    "    \n",
    "plt.scatter(t, y, marker='o')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We nicely see that most data points follow the PPC 99.5% probability range (light green).\n",
    "\n",
    "**Except** for one point (near x=2, y=4). This is the outlier I snuck in when generating the data.\n",
    "\n",
    "At this point we could adjust the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the parameter posterior probability distribution\n",
    "\n",
    "A classic corner plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultranest.plot import cornerplot\n",
    "cornerplot(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next\n",
    "\n",
    "These were just some of the basic elements of a Bayesian workflow:\n",
    "\n",
    "* Exploratory data analysis\n",
    "* Specifying likelihood & priors\n",
    "* Generating a prior flip-book\n",
    "* Posterior predictive checks\n",
    "\n",
    "The other tutorials cover other aspects, such as \n",
    "\n",
    "* verifying the model with simulated data\n",
    "* comparing models\n",
    "\n",
    "\n",
    "Further reading (more MCMC-related):\n",
    "\n",
    "* https://mc-stan.org/workshops/stancon2018_intro/Bayesian%20workflow.pdf\n",
    "* https://betanalpha.github.io/assets/case_studies/principled_bayesian_workflow.html\n",
    "* https://arxiv.org/abs/1709.01449"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
